export const Project3=()=>{
    return<>
        <div className="project1">
            <div className="head">
                <div className="heading">
                    <h1>Project 3</h1>
                </div>
                <div className="description">
                    <h2><b>Project Description: Gesture Recognition System Using Machine Learning</b></h2>
                    <p>The Gesture Recognition System is an innovative application leveraging machine learning to interpret and analyze human gestures in real-time. 
                    Equipped with a camera interface, this system captures gestures, processes them using trained ML models, and outputs their corresponding meanings. 
                    It provides an intuitive way for users to interact with digital systems through natural body movements, offering wide-ranging applications across 
                    industries.</p>
                    <h2><b>Features:</b></h2>
                    <p>1. Real-Time Gesture Recognition:

                    Utilizes a live camera feed to capture hand and body gestures dynamically.
                    Processes video frames in real time, ensuring instantaneous gesture recognition.</p>
                    <p>2. Machine Learning-Powered Classification:

                    Trained ML models detect and classify various gestures, such as hand signals, body movements, or facial expressions.
                    High accuracy achieved through deep learning techniques like Convolutional Neural Networks (CNNs).</p>
                    <p>3. Output Interpretation:

                    Recognized gestures are translated into predefined meanings or commands, displayed on-screen or sent as input to connected systems.
                    Supports customizable gestures for domain-specific applications (e.g., sign language, gaming commands, or robotic controls).</p>
                    <p>4. Camera Integration:

                    Supports both built-in and external cameras for gesture recording.
                    Provides optimized performance under varying lighting and environmental conditions.</p>
                    <p>5. User-Friendly Interface:

                    Interactive and responsive UI for live feedback on recognized gestures.
                    Displays detected gestures alongside their meanings in real time.</p>
                    <p>6. Offline and Online Modes:

                    Operates offline with locally stored models or online with cloud-based processing for advanced tasks.</p>
                    <p>7. Gesture Training Module:

                    Allows users to define and train the system on custom gestures for personalized use cases.</p>
                <h2><b>Technology Stack:</b></h2>
                <p>Frontend: React.js or Flutter for a responsive user interface.</p>
                <p>Backend: Python with Flask or FastAPI for managing real-time p</p>
                <p>Machine Learning: TensorFlow or PyTorch for training and deplo</p>
                <p>Camera Integration: OpenCV for real-time video capture and pre</p>
                <p>Cloud Services: AWS or Google Cloud for large-scale model training and storage, if needed.</p>
                <a className='link' href="https://github.com/Samarth0777/Gesture_Recognition">Visit here</a>
                </div>
            </div>

        </div>
    </>
}